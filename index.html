<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>In-Jae Lee</title>
  
  <meta name="author" content="In-Jae Lee">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="images/injaelee.png" src="images/injaelee.png">

</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>In-Jae Lee</name>
              </p>
              <p>I am a second-year Ph.D. candidate supervised by <a href="https://jaesik.info//">Jaesik Park</a> at the <a href="https://jaesik.info/lab">Visual & Geometric Intelligence Lab </a>  in <a href="https://en.snu.ac.kr/index.html"> SNU</a>.
              </p>
              <p>
                Before starting my Ph.D., I obtained a mastser's degree from Graduate School of Mobility at <a href="https://www.kaist.ac.kr/kr/"> KAIST</a>, where I was a memeber of <a href="http://vdclab.kaist.ac.kr/index.php">AXE Lab</a>. Before that, I earned a bachelor's degree in Automotive Engineering from the <a href="https://www.kookmin.ac.kr/user/index.do">KMU</a>.


              <p style="text-align:center">
                <a href="mailto:injae1994@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://www.overleaf.com/read/spsdkyfhpgcg#22f361">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=Nc1XmU8AAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/oliver0922">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/2injae/">Linkedin</a>

              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/injaelee.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/injaelee.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>News</heading>
                  <p>
                      <table style="width:100%; text-align: left;">
                        <tr>
                          <td> <strong>[2025.09]</strong> </td>
                          <td>  Our OpenBox, an automatic annotation pipeline for 3D bounding box, is accepted to <a href="https://nips.cc/"> NeurIPS 2025 </a>  as a spotlight!</td>
                        </tr>

                        <tr>
                          <td> <strong>[2025.01]</strong> </td>
                          <td>  Our  CRAB, a camera-radar fusion for 3D peception is accepted to <a href="https://2025.ieee-icra.org/"> ICRA 2025!</a> </td>
                        </tr>

                      </table>
                  </p>
              </td>
          </tr>
      </tbody></table>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
              I am interested in 3D computer vision, especially 3D perception and scene understanding for robot vision. My research focuses on multi-modal sensor fusion, including camera, LiDAR, and radar, to enhance the perception capabilities of autonomous systems. I am also passionate about leveraging visual foundation model for 3D perception.
              </p>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/openbox.png" alt="blind-date" width="160" height="100">
            </td>
            <td width="75%" valign="middle">
                <papertitle>OpenBox: Annotate Any 3D Bounding Boxes</papertitle>
              <br>
              <strong>In-Jae Lee*</strong>, Moongyeom Kim*, Kwonyoung Ryu, Pierre Musacchio and Jaesik Park
              <br>
              <strong>NeurIPS 2025 </strong> <font color="red"><strong>(Spotlight)</strong></font>

                                                  
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/crab.png" alt="blind-date" width="160" height="50">
            </td>
            <td width="75%" valign="middle">
                <papertitle>CRAB: Camera-Radar Fusion for Reducing Depth Ambiguity in Backward Projection based View Transformation</papertitle>
              </a>
              <br>
              <strong>In-Jae Lee</strong>, Sihwan Hwang, Youngseok Kim, Wonjune Kim, Sanmin Kim and Dongsuk Kum 
              <br>
              <strong>ICRA 2025 </strong>

                                                  
              <a href="https://arxiv.org/abs/2509.05785">paper</a>                                   
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/p2d.png" alt="blind-date" width="160" height="60">
            </td>
            <td width="75%" valign="middle">
                <papertitle>Predict to Detect: Prediction-guided 3D Object Detection using Sequential Images</papertitle>
              </a>
              <br>
             Sanmin Kim, Youngseok Kim, <strong>In-Jae Lee</strong> and Dongsuk Kum
              <br>
              <strong>ICCV 2023 </strong>

                                                  
              <a href="https://arxiv.org/abs/2306.08528">paper</a> |                                     
              <a href="https://github.com/sanmin0312/P2D" type="text/html">code</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/crn.png" alt="blind-date" width="160" height="50">
            </td>
            <td width="75%" valign="middle">
                <papertitle>CRN: Camera Radar Net for Accurate, Robust, Efficient 3D Perception</papertitle>
              </a>
              <br>
              Youngseok Kim, Juyeb shin, Sanmin Kim, </S> <strong>In-Jae Lee</strong>, Jun Won Choi and Dongsuk Kum
              <br>
              <strong>ICCV 2023 </strong>
                                                  
              <a href="https://arxiv.org/abs/2304.00670">paper</a> |                                     
              <a href="https://www.youtube.com/watch?v=hMWe2yjzwQ0">video</a> |
              <a href="https://github.com/youngskkim/CRN" type="text/html">code</a>
            </td>
          </tr>



        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
              <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                      This website's source code is from <a href="https://jonbarron.info/">Jon Barron</a>.
                  </p>
              </td>
          </tr>
      </tbody></table>

      </td>
    </tr>
  </table>
  <script defer id="clstr_globe" src="https://clustrmaps.com/globe.js?d=uKSkGfBsW2HkTKS1nP5NgKl9ErynLjwL_ivV9KVSolo"></script>
  <script>
    // Scale down the floating ClustrMaps globe widget
    window.addEventListener('load', () => {
      const globe = document.querySelector('div[id^="clustr"], div[class*="clustr"]');
      if (globe) {
        const applyScale = () => {
          const scale = window.innerWidth <= 600 ? 0.6 : 0.75; // mobile smaller
          globe.style.transform = `scale(${scale})`;
          globe.style.transformOrigin = 'bottom right';
          globe.style.right = '12px';
          globe.style.bottom = '12px';
        };
        applyScale();
        window.addEventListener('resize', applyScale);
      }
    });
  </script>
</body>

</html>
